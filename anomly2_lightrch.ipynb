{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Anomaly Detection with Anomalib: Setup Script\n",
    "# ----------------------------------------------\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from anomalib import TaskType\n",
    "import anomalib\n",
    "from anomalib.data import Folder, MVTecAD\n",
    "from anomalib.models import (\n",
    "    Patchcore, Padim, Stfpm, Draem, EfficientAd, Fastflow, Cflow\n",
    ")\n",
    "from anomalib.deploy.inferencers import TorchInferencer\n",
    "from anomalib.utils.normalization import NormalizationMethod\n",
    "from anomalib.utils.post_processing import superimpose_anomaly_map\n",
    "from anomalib.data.utils import TestSplitMode\n",
    "print(\"Anomalib version:\", anomalib.__version__)\n",
    "seed_everything(0)\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the datamodule using Folder-based dataset\n",
    "datamodule = Folder(\n",
    "    name=\"my_dataset\",\n",
    "    root=r\"D:\\Anomaly_detecion\\hazelnut_toy\",\n",
    "    normal_dir=\"good\",\n",
    "    abnormal_dir=\"crack\",  # only if you have it you can do it with good only\n",
    "    normal_split_ratio=0.1,\n",
    "\n",
    "    train_batch_size=16,\n",
    "    eval_batch_size=16,\n",
    ")\n",
    "\n",
    "datamodule.setup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Padim(\n",
    "    backbone=\"resnet18\",  # Feature extraction backbone\n",
    "    layers=[\"layer1\", \"layer2\", \"layer3\"],  # Layers to extrxtrct\n",
    "    pre_trained=True,  # Use pretrained weights\n",
    "    n_features=100,  # Number of features\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f6b580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\sam\\anaconda3\\envs\\anomalib-gpu\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name           | Type          | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | pre_processor  | PreProcessor  | 0      | train\n",
      "1 | post_processor | PostProcessor | 0      | train\n",
      "2 | evaluator      | Evaluator     | 0      | train\n",
      "3 | model          | PadimModel    | 2.8 M  | train\n",
      "---------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "69        Modules in eval mode\n",
      "c:\\Users\\sam\\anaconda3\\envs\\anomalib-gpu\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\sam\\anaconda3\\envs\\anomalib-gpu\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907cb82d8a2b4824b4c80302e8bdce0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fb9e6c5962463f832585f20394c731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "engine = Engine(\n",
    "    max_epochs=1,  # PaDiM needs only one epoch\n",
    "    accelerator=\"auto\",  # Automatically detect GPU/CPU\n",
    "    devices=1,  # Number of devices to use\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "engine.fit(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "542c91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('v0/weights/lightning/weights/torch/model.pt')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = engine.trainer.checkpoint_callback.best_model_path.split('\\\\')\n",
    "engine.export(model, ExportType.TORCH, export_root = \"/\".join(path_list[6:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8595c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: Evaluator, ImageVisualizer, PostProcessor, PreProcessor\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\sam\\anaconda3\\envs\\anomalib-gpu\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d6fed4d0234a52a2188e4ddfbd8fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:anomalib.visualization.image.item_visualizer:Field 'gt_mask' is None in ImageItem. Skipping visualization.\n",
      "WARNING:anomalib.visualization.image.item_visualizer:Field 'gt_mask' is None in ImageItem. Skipping visualization.\n",
      "WARNING:anomalib.visualization.image.item_visualizer:Field 'gt_mask' is None in ImageItem. Skipping visualization.\n",
      "WARNING:anomalib.visualization.image.item_visualizer:Field 'gt_mask' is None in ImageItem. Skipping visualization.\n",
      "WARNING:anomalib.visualization.image.item_visualizer:Field 'gt_mask' is None in ImageItem. Skipping visualization.\n",
      "WARNING:anomalib.visualization.image.item_visualizer:Field 'gt_mask' is None in ImageItem. Skipping visualization.\n",
      "c:\\Users\\sam\\anaconda3\\envs\\anomalib-gpu\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric AUROC was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\sam\\anaconda3\\envs\\anomalib-gpu\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric F1Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 1.0, 'image_F1Score': 0.5}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.test(datamodule=datamodule, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdf20813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.]], device='cuda:0'),\n",
       " tensor([False], device='cuda:0'),\n",
       " ImageBatch(image=Image([[[[0.8078, 0.8039, 0.8039,  ..., 0.8157, 0.8235, 0.8000],\n",
       "          [0.8078, 0.8157, 0.8157,  ..., 0.8118, 0.8039, 0.7961],\n",
       "          [0.7961, 0.8078, 0.8000,  ..., 0.8118, 0.8196, 0.8157],\n",
       "          ...,\n",
       "          [0.8392, 0.8235, 0.8392,  ..., 0.8196, 0.8078, 0.8157],\n",
       "          [0.8392, 0.8314, 0.8471,  ..., 0.8157, 0.8039, 0.7843],\n",
       "          [0.8314, 0.8392, 0.8392,  ..., 0.8196, 0.8157, 0.8078]],\n",
       " \n",
       "         [[0.7804, 0.7725, 0.7725,  ..., 0.7804, 0.7882, 0.7647],\n",
       "          [0.7765, 0.7843, 0.7843,  ..., 0.7765, 0.7686, 0.7608],\n",
       "          [0.7647, 0.7765, 0.7686,  ..., 0.7765, 0.7843, 0.7804],\n",
       "          ...,\n",
       "          [0.8157, 0.8000, 0.8157,  ..., 0.7882, 0.7765, 0.7843],\n",
       "          [0.8157, 0.8078, 0.8235,  ..., 0.7843, 0.7804, 0.7608],\n",
       "          [0.8078, 0.8157, 0.8157,  ..., 0.7961, 0.7922, 0.7843]],\n",
       " \n",
       "         [[0.2314, 0.2353, 0.2353,  ..., 0.2667, 0.2745, 0.2510],\n",
       "          [0.2392, 0.2471, 0.2471,  ..., 0.2627, 0.2549, 0.2471],\n",
       "          [0.2275, 0.2392, 0.2314,  ..., 0.2627, 0.2706, 0.2667],\n",
       "          ...,\n",
       "          [0.2824, 0.2667, 0.2824,  ..., 0.2588, 0.2471, 0.2549],\n",
       "          [0.2824, 0.2745, 0.2902,  ..., 0.2549, 0.2471, 0.2275],\n",
       "          [0.2745, 0.2824, 0.2824,  ..., 0.2627, 0.2588, 0.2510]]]],\n",
       "       device='cuda:0', ), gt_label=None, gt_mask=None, mask_path=None, anomaly_map=Mask([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), pred_score=tensor([[0.]], device='cuda:0'), pred_mask=Mask([[[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]]], device='cuda:0'), pred_label=tensor([False], device='cuda:0'), explanation=None, image_path=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from anomalib.deploy.inferencers import TorchInferencer\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image\n",
    "image_path = r\"D:\\Anomaly_detecion\\hazelnut_toy\\good\\15.jpg\"\n",
    "print(\"sam\")\n",
    "image = Image.open(image_path).convert(\"RGB\")  # Convert image to RGB\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the inferencer\n",
    "inferencer = TorchInferencer(r'v0/weights/lightning/weights/torch/model.pt')\n",
    "\n",
    "# Perform inference\n",
    "results = inferencer.predict(image)  # Unsqueeze to add batch dimension\n",
    "results.pred_score ,results.pred_label,results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08f89843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<anomalib.deploy.inferencers.torch_inferencer.TorchInferencer object at 0x00000192AAD54B80>\n",
      "🧠 Raw Anomaly Score     : 0.4988\n",
      "🎯 Threshold Used        : 0.4 (Reversed Logic)\n",
      "🏷️  Predicted Class Index: 1\n",
      "🔖 Predicted Class Label : Anomalous\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from anomalib.deploy.inferencers import TorchInferencer\n",
    "\n",
    "# Load image\n",
    "image = Image.open(r\"D:\\Anomaly_detecion\\hazelnut_toy\\crack\\04.jpg\").convert(\"RGB\")\n",
    "\n",
    "# Initialize inferencer\n",
    "inferencer = TorchInferencer(path=r\"v0/weights/lightning/weights/torch/model.pt\")\n",
    "print(inferencer)\n",
    "\n",
    "# Perform inference\n",
    "result = inferencer.predict(image)\n",
    "\n",
    "# Get raw anomaly score\n",
    "pred_score = result.pred_score.item()\n",
    "\n",
    "\n",
    "# Custom reversed threshold logic\n",
    "custom_threshold = 0.4\n",
    "pred_label = 1 if pred_score >custom_threshold else 0  # 🔁 REVERSE\n",
    "label_name = \"Anomalous\" if pred_label == 1 else \"Normal\"\n",
    "\n",
    "# Print results\n",
    "print(f\"🧠 Raw Anomaly Score     : {pred_score:.4f}\")\n",
    "print(f\"🎯 Threshold Used        : {custom_threshold} (Reversed Logic)\")\n",
    "print(f\"🏷️  Predicted Class Index: {pred_label}\")\n",
    "print(f\"🔖 Predicted Class Label : {label_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
